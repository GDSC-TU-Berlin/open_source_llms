{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!curl -L 'https://drive.google.com/uc?export=download&id=1gdmIrgETs42Mb2MyQnjo0KAPrZyKGLsY' -o data.zip\n",
    "!unzip data.zip"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd8eb26e6aecc0ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_dataset():\n",
    "    dataset = []\n",
    "    for file in os.listdir(\"data/original\"):\n",
    "        path_original = os.path.join(\"data/original\", file)\n",
    "        path_simplified = os.path.join(\"data/simplified\", file)\n",
    "        \n",
    "        text = \"\"\n",
    "        with open(path_original, \"r\") as f:\n",
    "            text += \"REPORT:\\n\"\n",
    "            text += f.read()\n",
    "        \n",
    "        with open(path_simplified, \"r\") as f:\n",
    "            text += \"SUMMARY:\\n\"\n",
    "            text += f.read()\n",
    "        dataset.append(text)\n",
    "    \n",
    "    return dataset\n",
    "dataset = load_dataset()\n",
    "dataset_train, dataset_val = dataset[:int(len(dataset)*0.8)], dataset[int(len(dataset)*0.8):]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b02455410d675895",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(prompt,truncation=True,max_length=1500)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30b19b8724d1a114",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_tokenized_train = list(map(generate_and_tokenize_prompt, dataset_train))\n",
    "data_tokenized_val = list(map(generate_and_tokenize_prompt, dataset_val))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa8b44b4c40a72fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_tokenized_train[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2bea724e291e537",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    r= 16,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout= 0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        \"lm_head\",]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1157d8bc16f0dfe5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data_tokenized_train,\n",
    "    eval_dataset=data_tokenized_val,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"results\",\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=1000,\n",
    "        learning_rate=2.5e-5, \n",
    "        bf16=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=50,            \n",
    "        logging_dir=\"./logs\",      \n",
    "        save_strategy=\"steps\",     \n",
    "        save_steps=50,                \n",
    "        evaluation_strategy=\"steps\", \n",
    "        eval_steps=50,               \n",
    "        do_eval=True,                \n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  \n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6685aed33c486fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Da das training sehr lange dauert, wird es hier abgebrochen. Und wir benutzen ein checkpoint den wir vorher gespeichert haben."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f16e2bf5719ce431"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!curl -L \"https://file.io/ez5XKjM0PtFm\" -o checkpoint-500.zip\n",
    "!unzip checkpoint-500.zip -d results/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42bbe67db25b9c24",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", low_cpu_mem_usage=True,\n",
    "    return_dict=True,torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"results/checkpoint-500\")\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.save_pretrained(\n",
    "    \"./results/final_model/\", safe_serialization=True, max_shard_size=\"2GB\"\n",
    ")\n",
    "tokenizer.save_pretrained(\"./results/final_model/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd16c8ce59a23ebf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!git clone https://github.com/ggerganov/llama.cpp.git\n",
    "!make -C llama.cpp\n",
    "!pip install -r llama.cpp/requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef00783394add00a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python llama.cpp/convert.py ./results/final_model/ --outfile ./results/final_model_fp16.gguf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3595c558859f642c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!./llama.cpp/quantize ./results/final_model_fp16.gguf ./results/final_model_Q4.gguf Q4_0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be006d93bc6f29ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a7833a292fe6290"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llama = Llama(\n",
    "    \"./results/final_model_Q4.gguf\",\n",
    "    n_ctx=2048,\n",
    "    n_gpu_layers=-1, # Verschiebt die Berechnung auf die GPU\n",
    "    verbose=False, # Entfernt die Logausgaben\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c93df1600ff96dbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "Chief Complaint: Chronic abdominal pain and unintentional weight loss.\n",
    "\n",
    "Patient History and Clinical Presentation: The patient, a 45-year-old female with a past medical history significant for type 2 diabetes mellitus and hypertensive cardiovascular disease, presents with a complaint of progressive and persistent abdominal pain over the past 6 months, accompanied by a marked unintentional weight loss of approximately 15% of her body weight within the same period. The abdominal pain is described as diffusely located, dull, and poorly localized, with intermittent exacerbations of moderate intensity, particularly post-prandial. The patient reports significant anorexia but denies any correlation with dietary intake, dysphagia, or odynophagia. No changes in bowel habits, blood in stools, or jaundice observed. The patient mentions fatigue and occasional night sweats but denies fever, changes in urine color, or family history of gastrointestinal cancers.\n",
    "\n",
    "Diagnostic Workup and Findings:\n",
    "1. Comprehensive blood work including CBC, CMP, inflammatory markers (CRP, ESR), and tumor markers (CA 19-9, CEA) was conducted, showing mild anemia and elevated inflammatory markers; tumor markers were within normal ranges.\n",
    "2. Abdominal ultrasound revealed no significant hepatic, gallbladder, or kidney abnormalities; however, it indicated pancreatic head enlargement.\n",
    "3. A subsequent CT scan of the abdomen and pelvis with contrast confirmed the presence of a hypoattenuating mass in the head of the pancreas, measuring approximately 3.5 cm, with no definitive evidence of metastasis. There were also signs of mild intra- and extrahepatic biliary ductal dilatation.\n",
    "4. Endoscopic ultrasound (EUS) guided biopsy of the pancreatic mass was performed, confirming the presence of adenocarcinoma.\n",
    "\n",
    "Differential Diagnosis:\n",
    "1. Pancreatic Adenocarcinoma (primary diagnosis based on imaging and biopsy).\n",
    "2. Chronic pancreatitis: Considered due to the presentation of abdominal pain and weight loss; however, the presence of a distinct mass and the biopsy result favor malignancy.\n",
    "3. Gastric or duodenal ulcers: Typically present with epigastric pain often alleviated by eating, which is not consistent with this patient's symptoms.\n",
    "4. Celiac disease: Could explain symptoms but lacks the specificity of imaging findings associated with intestinal villi atrophy, and serological markers were negative.\n",
    "5. IBD (Inflammatory Bowel Disease): Location and nature of the pain, along with a lack of diarrheal symptoms, make this less likely.\n",
    "\n",
    "Diagnosis: Stage IIA (T3N0M0 based on the TNM classification) pancreatic adenocarcinoma.\n",
    "\n",
    "Plan and Recommendations:\n",
    "Given the patient’s diabetes and cardiovascular status, multidisciplinary evaluation including gastroenterology, oncology, endocrinology, and cardiology is imperative for a comprehensive treatment plan.\n",
    "\n",
    "1. Medical management: Initiate glucose and hypertension control optimization in collaboration with endocrinology and cardiology.\n",
    "2. Oncological management: Considering the localized nature of the pancreatic cancer without evidence of distant metastasis, the patient is a candidate for surgical resection likely followed by adjuvant chemotherapy. The surgical approach would initially involve a Whipple procedure (pancreaticoduodenectomy) given the tumor's location.\n",
    "3. Referral to a dietician for nutritional support, focusing on managing weight loss and optimizing nutritional status both pre-and post-operatively.\n",
    "4. Regular follow-ups for monitoring tumor response and managing the side effects of subsequent therapies.\n",
    "\n",
    "Importantly, discussions around the prognosis, expected outcomes, and the importance of advance care planning should be initiated early in the treatment process, considering the aggressive nature of pancreatic cancer and the potential for significant treatment-associated morbidity. The care team should also ensure to engage in empathetic communication, providing the patient with the necessary psychological support throughout her cancer journey.\n",
    "\"\"\"\n",
    "\n",
    "response = llama(f\"REPORT:\\n{example}SUMMARY:\\n\", max_tokens=1000)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ace1816d1f16fdf7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcde80d7601ba955"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
